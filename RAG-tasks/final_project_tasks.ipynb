{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9e4409-52ac-4436-a017-0fdc82b49e02",
   "metadata": {},
   "source": [
    "# Final Project: AI RAG Assistant Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f8291d6-c26d-4fc7-bee2-f3a49579edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install chromadb\n",
    "!pip install langchain_community\n",
    "!pip install pypdfium2\n",
    "!pip install sentence-transformers\n",
    "!pip install wget\n",
    "\n",
    "# Suppress warnings and clear all output from PIP\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa3a29-e7f3-4bd7-aa16-555f5a655a26",
   "metadata": {},
   "source": [
    "## Task 1: Load document using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac3b405-20ed-40ae-8cf9-189ecb4f0406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A Comprehensive Review of Low-Rank\\n'\n",
      " 'Adaptation in Large Language Models for\\n'\n",
      " 'Efficient Parameter Tuning\\n'\n",
      " 'September 10, 2024\\n'\n",
      " 'Abstract\\n'\n",
      " 'Natural Language Processing (NLP) often involves pre-training large\\n'\n",
      " 'models on extensive datasets and then adapting them for specific tasks\\n'\n",
      " 'through fine-tuning. However, as these models grow larger, like GPT-3\\n'\n",
      " 'with 175 billion parameters, fully fine-tuning them becomes '\n",
      " 'computa\\x02tionally expensive. We propose a novel method called LoRA '\n",
      " '(Low-Rank\\n'\n",
      " 'Adaptation) that significantly reduces the overhead by freezing the '\n",
      " 'orig\\x02inal model weights and only training small rank decomposition '\n",
      " 'matrices.\\n'\n",
      " 'This leads to up to 10,000 times fewer trainable parameters and reduces\\n'\n",
      " 'GPU memory usage by three times. LoRA not only maintains but some\\x02times '\n",
      " 'surpasses fine-tuning performance on models like RoBERTa, De\\x02BERTa, '\n",
      " 'GPT-2, and GPT-3. Unlike other methods, LoRA introduces\\n'\n",
      " 'no extra latency during inference, making it more efficient for practical\\n'\n",
      " 'applications. All relevant code and mo')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from pprint import pprint\n",
    "\n",
    "pdf_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WgM1DaUn2SYPcCg_It57tA/A-Comprehensive-Review-of-Low-Rank-Adaptation-in-Large-Language-Models-for-Efficient-Parameter-Tuning-1.pdf\"\n",
    "loader = PyPDFium2Loader(pdf_url)\n",
    "data = loader.load()\n",
    "pprint(data[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee51948-a4ab-4001-814c-825eb0a3cdfd",
   "metadata": {},
   "source": [
    "## Task 2: Apply text splitting techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46a3fd0-055a-4e11-95b6-e21a8d4eeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_text = r\"\"\"\n",
    "\n",
    "    \\documentclass{article}\n",
    "\n",
    "    \\begin{document}\n",
    "\n",
    "    \\maketitle\n",
    "\n",
    "    \\section{Introduction}\n",
    "\n",
    "    Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in various natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
    "\n",
    "    \\subsection{History of LLMs}\n",
    "\n",
    "    The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
    "    \n",
    "    \\subsection{Applications of LLMs}\n",
    "    \n",
    "    LLMs have many applications in the industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
    "    \n",
    "    \\end{document}\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2beb0f8f-f71a-4048-b019-5648e15fc3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='\\\\documentclass{article}\\n\\n    \\\\begin{document}'),\n",
       " Document(metadata={}, page_content='\\\\maketitle\\n\\n    \\\\section{Introduction}\\n\\n    Large language'),\n",
       " Document(metadata={}, page_content='models (LLMs) are a type of machine learning model that can'),\n",
       " Document(metadata={}, page_content='be trained on vast amounts of text data to generate'),\n",
       " Document(metadata={}, page_content='human-like language. In recent years, LLMs have made'),\n",
       " Document(metadata={}, page_content='significant advances in various natural language processing'),\n",
       " Document(metadata={}, page_content='tasks, including language translation, text generation, and'),\n",
       " Document(metadata={}, page_content='sentiment analysis.\\n\\n    \\\\subsection{History of LLMs}'),\n",
       " Document(metadata={}, page_content='The earliest LLMs were developed in the 1980s and 1990s,'),\n",
       " Document(metadata={}, page_content='but they were limited by the amount of data that could be'),\n",
       " Document(metadata={}, page_content='processed and the computational power available at the'),\n",
       " Document(metadata={}, page_content='time. In the past decade, however, advances in hardware and'),\n",
       " Document(metadata={}, page_content='software have made it possible to train LLMs on massive'),\n",
       " Document(metadata={}, page_content='datasets, leading to significant improvements in'),\n",
       " Document(metadata={}, page_content='performance.\\n    \\n    \\\\subsection{Applications of LLMs}'),\n",
       " Document(metadata={}, page_content='LLMs have many applications in the industry, including'),\n",
       " Document(metadata={}, page_content='chatbots, content creation, and virtual assistants. They'),\n",
       " Document(metadata={}, page_content='can also be used in academia for research in linguistics,'),\n",
       " Document(metadata={}, page_content='psychology, and computational linguistics.'),\n",
       " Document(metadata={}, page_content='\\\\end{document}')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "latex_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.LATEX,\n",
    "    chunk_size=60,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "latex_docs = latex_splitter.create_documents([latex_text])\n",
    "latex_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826c585-1477-4b6d-bded-23f5feb18025",
   "metadata": {},
   "source": [
    "## Task 3: Embed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75f26a2f-7d16-4dab-bd3e-e54605fd1ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02710619755089283,\n",
       " 0.011331832036376,\n",
       " -0.0019523875089362264,\n",
       " -0.036951325833797455,\n",
       " 0.01776488684117794]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "query = \"How are you?\"\n",
    "query_result = embedding.embed_query(query)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037acfb8-c812-4491-a4d1-f97b36e391ba",
   "metadata": {},
   "source": [
    "## Task 4: Create and configure vector databases to store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "224fa95c-9ae6-46f0-b181-c0a007692a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'new-Policies.txt'}, page_content='Our Mobile Phone Policy defines standards for responsible use of mobile devices within the'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='4. Mobile Phone Policy'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='Consequences: Non-compliance with this policy may result in disciplinary actions, including'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy promotes the safe and responsible use of digital communication tools in line with our')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the text from file:\n",
    "# uncomment the following three lines if new-Policies.txt is not yet downloaded\n",
    "# import wget\n",
    "# file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\"\n",
    "# file_name = wget.download(file_url)\n",
    "file_name = \"new-Policies.txt\"\n",
    "loader = TextLoader(file_name)\n",
    "data = loader.load()\n",
    "\n",
    "# Split text into chunks:\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Create the vector database:\n",
    "# note: use the embedding from Task 3\n",
    "ids = [str(i) for i in range(len(chunks))]\n",
    "vector_db = Chroma.from_documents(chunks, embedding, ids=ids)\n",
    "\n",
    "# Conduct similarity search:\n",
    "query = \"Smoking policy\"\n",
    "docs = vector_db.similarity_search(query, k=5)  # show top 5 results\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276e4ea-bf17-4ee2-9fef-5de7933d6a64",
   "metadata": {},
   "source": [
    "## Task 5: Develop a retriever to fetch document segments based on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f84cc7b0-d41e-468a-9494-51e80a316207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'new-Policies.txt'}, page_content='3. Internet and Email Policy'),\n",
       " Document(metadata={'source': 'new-Policies.txt'}, page_content='Our Internet and Email Policy ensures the responsible and secure use of these tools within our')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: The file new-Policies.txt is already loaded and saved as a Chroma\n",
    "# database from Task 4 and stored in `vector_db`.\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "query = \"Email policy\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e810a4-ee4c-4a12-b732-973c76349c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
